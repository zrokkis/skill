# Êñá‰ª∂Âêç: ag_indexer.py
import os, pickle
from sentence_transformers import SentenceTransformer


# Ëé∑ÂèñÂΩìÂâçËÑöÊú¨ÊâÄÂú®ÁõÆÂΩïÁöÑÁà∂Á∫ßÁõÆÂΩï‰∏ãÁöÑ prompt Êñá‰ª∂Â§π
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
SKILLS_DIR = os.path.abspath(os.path.join(CURRENT_DIR, "../../assets/expert_frameworks"))
CACHE_FILE = os.path.join(CURRENT_DIR, "skills_cache.pkl")

MODEL_NAME = 'paraphrase-multilingual-mpnet-base-v2'

def get_model_path():
    """‰ºòÂÖàÁ∫ß: ÁéØÂ¢ÉÂèòÈáè -> ÂÜÖÁΩÆÁõÆÂΩï -> ËøúÁ®ã"""
    env_path = os.environ.get("PEER_MODEL_PATH")
    if env_path and os.path.exists(env_path): return env_path
    
    local_path = os.path.join(os.path.dirname(CURRENT_DIR), "../../models", MODEL_NAME)
    if os.path.exists(local_path): return local_path
    
    return MODEL_NAME

def build():
    # ‰ºòÂÖàÂä†ËΩΩÊú¨Âú∞Ê®°Âûã
    model_path = get_model_path()
    print(f"üì¶ Indexing with model from: {model_path}")
    model = SentenceTransformer(model_path)
    skills_data, descriptions = [], []

    for root, _, files in os.walk(SKILLS_DIR):
        if 'SKILL.md' in files:
            path = os.path.join(root, 'SKILL.md')
            with open(path, 'r', encoding='utf-8') as f:
                content = f.read()
                # ‰ΩøÁî®Ê≠£ÂàôÊèêÂèñ YAML frontmatter ‰∏≠ÁöÑ description
                # ÂåπÈÖç key: value Ê†ºÂºèÔºåÊîØÊåÅÂ§öË°åÔºàËôΩÁÑ∂ÈÄöÂ∏∏ÊòØ‰∏ÄË°åÔºå‰ΩÜÊ≠£ÂàôÂÖºÂÆπÊÄßÊõ¥Â•ΩÔºâ
                import re
                match = re.search(r'^---\s+.*?description:\s*(.*?)\s+---', content, re.DOTALL | re.VERBOSE)
                
                if match:
                    desc = match.group(1).strip()
                else:
                    # Â¶ÇÊûúÊ≤°Êúâ yaml Â§¥ÔºåÂ∞ùËØïÂõûÈÄÄÂà∞ÊóßÈÄªËæëÊàñËÆæ‰∏∫Êñá‰ª∂Âêç
                    parts = content.split('## Description')
                    if len(parts) > 1:
                        desc = parts[-1].split('##')[0].strip()
                    else:
                        print(f"‚ö†Ô∏è Warning: No description found for {os.path.basename(root)}")
                        desc = os.path.basename(root)
                
                skills_data.append({'name': os.path.basename(root), 'path': path})
                descriptions.append(desc)

    embeddings = model.encode(descriptions)
    with open(CACHE_FILE, 'wb') as f:
        pickle.dump({'metadata': skills_data, 'embeddings': embeddings}, f)
    print(f"‚úÖ Â∑≤Á¥¢Âºï {len(descriptions)} ‰∏™Ê°ÜÊû∂Ëá≥ {CACHE_FILE}")

if __name__ == "__main__": build()