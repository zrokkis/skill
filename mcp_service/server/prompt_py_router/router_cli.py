import os
import pickle
import re
from mcp.server.fastmcp import FastMCP
from sentence_transformers import SentenceTransformer, util

mcp = FastMCP("Prompt Router Service")

CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
CACHE_FILE = os.path.join(CURRENT_DIR, "skills_cache.pkl")
MODEL_NAME = 'paraphrase-multilingual-mpnet-base-v2'

_model = None
_data = None

def get_model_path():
    env_path = os.environ.get("PEER_MODEL_PATH")
    if env_path and os.path.exists(env_path): return env_path
    # ç»Ÿä¸€æ¢æµ‹é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ mcp_service/models/
    local_path = os.path.join(os.path.dirname(os.path.dirname(CURRENT_DIR)), "models", MODEL_NAME)
    if os.path.exists(local_path): return local_path
    return MODEL_NAME

def get_resources():
    global _model, _data
    if _model is None:
        model_path = get_model_path()
        _model = SentenceTransformer(model_path)
    if _data is None:
        if not os.path.exists(CACHE_FILE):
            from ag_indexer import build
            build()
        with open(CACHE_FILE, 'rb') as f:
            _data = pickle.load(f)
    return _model, _data

@mcp.tool()
def search_skill(query: str, top_k: int = 3) -> str:
    model, data = get_resources()
    query_embedding = model.encode(query, convert_to_tensor=True)
    hits = util.semantic_search(query_embedding, data['embeddings'], top_k=top_k)
    top_results = hits[0]
    
    results = []
    for hit in top_results:
        score = hit['score']
        meta = data['metadata'][hit['corpus_id']]
        rel_path = meta['path']
        abs_path = os.path.abspath(os.path.join(CURRENT_DIR, rel_path))
        
        desc = "No description available"
        if os.path.exists(abs_path):
            with open(abs_path, 'r', encoding='utf-8') as f:
                content = f.read()
                match = re.search(r'description:\s*(.*?)\n', content)
                if match: desc = match.group(1).strip()
        
        results.append(f"åˆ†æ•°: {score:.4f}\nåç§°: {meta['name']}\nè·¯å¾„: {abs_path}\næè¿°: {desc}\n" + "-"*20)
    return "\n".join(results)

@mcp.tool()
def prompt(query: str) -> str:
    model, data = get_resources()
    query_embedding = model.encode(query, convert_to_tensor=True)
    hits = util.semantic_search(query_embedding, data['embeddings'], top_k=1)
    best_hit = hits[0][0]
    meta = data['metadata'][best_hit['corpus_id']]
    
    # è¿˜åŸç»å¯¹è·¯å¾„
    rel_path = meta['path']
    prompt_file = os.path.abspath(os.path.join(CURRENT_DIR, rel_path))
    
    if not os.path.exists(prompt_file):
        return f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¡†æ¶æ–‡ä»¶ {prompt_file}"
        
    with open(prompt_file, 'r', encoding='utf-8') as f:
        full_content = f.read()
    
    optimized_response = f"""
### ğŸ¯ æ¨èæ¡†æ¶ï¼š{meta['name'].replace('_', ' ').upper()}
**åŒ¹é…ç½®ä¿¡åº¦**: {best_hit['score']:.4f}

---

# ğŸš€ ä¼˜åŒ–åçš„æç¤ºè¯ (Copy & Paste below)

ä½ ç°åœ¨æ˜¯ä¸€ä½åœ¨è¯¥é¢†åŸŸå…·å¤‡æ·±åšé€ è¯£çš„**è¡Œä¸šä¸“å®¶**ã€‚è¯·åŸºäºä»¥ä¸‹ç»“æ„åŒ–æ¡†æ¶ï¼Œå¤„ç†æˆ‘çš„æ ¸å¿ƒéœ€æ±‚ã€‚

### 1. æ ¸å¿ƒä»»åŠ¡ (The Task)
{query}

### 2. æ‰§è¡Œé€»è¾‘ä¸æ€è€ƒå‡†åˆ™ (Framework Directives)
è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹ç”± **[{meta['name']}]** æ¡†æ¶å®šä¹‰çš„æ‰§è¡Œæ ‡å‡†è¿›è¡Œè¾“å‡ºï¼š

{full_content}

---
**[ä½¿ç”¨è¯´æ˜]**: ä»¥ä¸Šå†…å®¹å·²ç”±äºå…¶å†…éƒ¨åŒ…å«å®Œæ•´çš„æ¡†æ¶é€»è¾‘ï¼Œè¯·ç›´æ¥å‘é€ç»™ AI å³å¯è·å¾—ä¸“å®¶çº§å“åº”ã€‚
"""
    return optimized_response

if __name__ == "__main__":
    mcp.run()